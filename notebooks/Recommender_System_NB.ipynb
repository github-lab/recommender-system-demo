{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Item Similarity Recommender Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender System\n",
    "A recommendation engine or  recommender system is a tool that makes prediction on what a user may or may not like, among a list of given items. Ratings for items across multiple users are algorithmically analysed are then used to recommend other items to the user that the user has not seen. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. \n",
    "\n",
    "pandas is well suited for many different kinds of data, including \n",
    "* Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
    "* Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
    "* Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
    "* Any other form of observational / statistical data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens Dataset\n",
    "MovieLens Data has been compiled by the GroupLens Research group at University of Minnesota.This MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. These data were created by 671 users between January 09, 1995 and October 16, 2016. This dataset was generated on October 17, 2016. \n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at http://grouplens.org/datasets/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of a recommender system based on the popular item-item collaborative filtering. It uses the centered cosine similarity metric (achieved by imputing all unrated items for each user with the mean rating of all items that the user has rated, and then taking a simple pearson correlation)\n",
    "\n",
    "The input to train the model is a dataframe with columns that represent *UserID, ItemID, and Rating* (need to indicate which is which during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class recommender():\n",
    "    def __init__(self):\n",
    "        self.item_sim=None\n",
    "        self.popular_items=None\n",
    "        self.ratings_df=None\n",
    "    \n",
    "    def fit(self, ratings_df, user_id, item_id, ratings):\n",
    "        assert type(ratings_df) == pd.core.frame.DataFrame\n",
    "        #assert set([user_id, item_id, rating]) < set(ratings_df.columns)\n",
    "        self.ratings_df=ratings_df.copy()\n",
    "        self.ratings_df=self.ratings_df.rename(columns={user_id: 'user_id', item_id: 'item_id', ratings: 'ratings'})\n",
    "        ratings_pivot=self.ratings_df.pivot(index='user_id', columns='item_id', values='ratings').transpose()\n",
    "        \n",
    "        for i in ratings_pivot.index:\n",
    "            ratings_pivot.loc[i,:].fillna((ratings_pivot.loc[i,:].mean()), inplace=True)\n",
    "        \n",
    "        self.item_frequency=self.ratings_df.dropna()['item_id'].value_counts()\n",
    "        self.ratings_pivot=ratings_pivot.copy() # remove later...not used\n",
    "        self.item_sim=ratings_pivot.transpose().corr().copy()\n",
    "        \n",
    "        self.min_rating=self.ratings_df['ratings'].min()\n",
    "        self.max_rating=self.ratings_df['ratings'].max()\n",
    "        self.find_popular_items()\n",
    "        \n",
    "    def find_popular_items(self):\n",
    "        self.popular_items=self.ratings_df.groupby(['item_id'])['ratings'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    def score(self,user_id, item_id, Nmax=20):\n",
    "        assert Nmax > 1\n",
    "        \n",
    "        items_rated_by_user=self.ratings_df[self.ratings_df['user_id']==user_id].dropna()\n",
    "\n",
    "        if items_rated_by_user.empty:\n",
    "            popular = self.popular_items.index[0] \n",
    "            return popular\n",
    "        \n",
    "        \n",
    "        item_sim_ratings=pd.DataFrame(self.item_sim.loc[item_id]).reset_index()\n",
    "        item_sim_ratings.columns=['item_id', 'sim']\n",
    "        \n",
    "        df_temp=items_rated_by_user.merge(item_sim_ratings).sort_values('sim', ascending=False).iloc[0:Nmax]\n",
    "        #retval= np.average(df_temp['ratings'], weights=df_temp['sim'])\n",
    "        \n",
    "        #this compensates for pathelogical cases where negative correltions dominate\n",
    "        ret_num = (df_temp['ratings'] * df_temp['sim']).sum()\n",
    "        ret_den = df_temp['sim'].abs().sum()\n",
    "        retval= ret_num/(1.0*ret_den)\n",
    "        \n",
    "        return np.clip(retval, self.min_rating, self.max_rating)\n",
    "    \n",
    "    def items_to_search(self, user_id, k=50):\n",
    "        items_rated_by_user=self.ratings_df[self.ratings_df['user_id']==user_id].dropna()['item_id']\n",
    "        items_not_rated_by_user=set(self.ratings_df['item_id'])-set(items_rated_by_user)\n",
    "        data=[self.item_frequency[i] for i in items_not_rated_by_user]\n",
    "        topk=pd.Series(data=data, index=items_not_rated_by_user).nlargest(k).index\n",
    "        \n",
    "        #return list(items_not_rated_by_user)\n",
    "        return list(topk)\n",
    "        \n",
    "    \n",
    "    def calculate_all_item_suggestions(self, user_id, max_suggestions=30):\n",
    "        item_search_list=self.items_to_search(user_id, k=max_suggestions)\n",
    "        scores={}\n",
    "        for item_id in item_search_list:\n",
    "            s= self.score(user_id,item_id, 30) #Nmax=30\n",
    "            scores[item_id]=s\n",
    "        return pd.Series(scores)\n",
    "    \n",
    "    def reco_topk_items_for_user(self, user_id, k=10, ret_json=False):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "            user_id - id of user for which recommendations are being requested\n",
    "            k - number of suggestions to return\n",
    "        outputs\n",
    "            item_id, predicted rating  - for top k recommended items\n",
    "        \"\"\"\n",
    "        try:\n",
    "            retval=self.calculate_all_item_suggestions(user_id).nlargest(k)\n",
    "            if ret_json:\n",
    "                return retval.to_json()\n",
    "            else:\n",
    "                return retval\n",
    "        except:\n",
    "            print('error has occured')\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: \n",
    "Let’s read in the inputs for training the recommender system, i.e. the movielens files. What are really need are the ratings that each user has given, to each item (movie in this case). This can simply be expressed as a 3-column table – userid, itemid, rating.  \n",
    "\n",
    "In the MovieLens 100K dataset, we are given the three files, u.users (for userids), u.items (for movie ids) and u.data(for ratings). \n",
    "\n",
    "We can use Pandas to read (using pandas.read_csv ) and then join these tables to get what we need very easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('/data/u.user', sep='|', names=u_cols,  encoding='latin-1')\n",
    "\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('/data/u.data', sep='\\t', names=r_cols,  encoding='latin-1')\n",
    "\n",
    "#Reading items file:\n",
    "i_cols = ['movie_id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items = pd.read_csv('/data/u.item', sep='|', names=i_cols,  encoding='latin-1')\n",
    "\n",
    "movies100k = pd.merge(pd.merge(ratings, users), items)[['user_id', 'movie_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies100k.shape #there are 100K movie ratings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "The recommender object uses the fit method to fit a recommendation model. It has a very simple interface - it takes a dataframe (movie100k in this case) as input, along with the column names of the dataframe that stand for userid, itemid, and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reco100k=recommender()\n",
    "reco100k.fit(movies100k, user_id='user_id', item_id='movie_id', ratings='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "Now that we have a model, we can use the model to predict i.e. to make recommendations for any userid. Note that we are working with “existing users”, i.e. users who have some rating history in the “system”. However, it can be extended in various ways to serve new users i.e. with no rating history, users with sparse history, etc., but we will not deal with that in this tutorial\n",
    "\n",
    "The below statement makes topk (in this case, best 10) recommendations for userid 25. It gives the 10 best items as well as their predicted ratings for user id 25, in form of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mr. Holland's Opus (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Braveheart (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Rock, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Jerry Maguire (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Scream (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Liar Liar (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Titanic (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Conspiracy Theory (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Saint, The (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie title\n",
       "14         Mr. Holland's Opus (1995)\n",
       "21                 Braveheart (1995)\n",
       "116                 Rock, The (1996)\n",
       "171  Empire Strikes Back, The (1980)\n",
       "236             Jerry Maguire (1996)\n",
       "287                    Scream (1996)\n",
       "293                 Liar Liar (1997)\n",
       "312                   Titanic (1997)\n",
       "327         Conspiracy Theory (1997)\n",
       "747                Saint, The (1997)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=reco100k.reco_topk_items_for_user(user_id=25)\n",
    "recos=items[items['movie_id'].isin(temp.index)]\n",
    "recos[['movie title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
